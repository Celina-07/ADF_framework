{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clayrs import content_analyzer as ca\n",
    "from clayrs import recsys as rs\n",
    "from clayrs import evaluation as eva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_to_df(e):\n",
    "    e_list = e.tolist()\n",
    "    df_e = pd.DataFrame(e_list)\n",
    "    return df_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performances(train, test, k=10):\n",
    "    em = eva.EvalModel(\n",
    "        [train],\n",
    "        [test],\n",
    "        metric_list=[\n",
    "            eva.PrecisionAtK(k, sys_average='macro'),\n",
    "            # eva.RecallAtK(k, sys_average='macro'),\n",
    "            # eva.FMeasureAtK(k, sys_average='macro'),\n",
    "            # eva.MRR(),\n",
    "            # eva.NDCGAtK(k),\n",
    "            # eva.CatalogCoverage(catalog),\n",
    "            # eva.GiniIndex()\n",
    "        ],    \n",
    "    )\n",
    "    sys_result, users_result = em.fit()\n",
    "    return sys_result, users_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triangular_matrix(m):\n",
    "    m_tri = m.where(np.triu(np.ones(m.shape),k=1).astype(bool))\n",
    "    return m_tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ILS(m):\n",
    "    m_tri = triangular_matrix(m).stack().reset_index()\n",
    "    m_tri.columns = ['i','j','similarity']\n",
    "    ils = (m_tri['similarity'].sum())/len(m_tri)\n",
    "    return ils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ils(recos, similarity_matrix, list_users):\n",
    "    dict_ils = {}\n",
    "    for u in tqdm(list_users):\n",
    "        recos_user = recos[recos['user_id']==u]\n",
    "        news_ids = recos_user['item_id'].tolist()\n",
    "        news_ids.sort()\n",
    "        sim_matrix_user = similarity_matrix[similarity_matrix.index.isin(news_ids)][news_ids]\n",
    "        ils_user = ILS(sim_matrix_user)\n",
    "        dict_key = {u:ils_user}\n",
    "        dict_ils.update(dict_key)\n",
    "    return dict_ils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_categories(initial_results):\n",
    "    results_categories = initial_results.copy()\n",
    "    results_categories = results_categories.rename(columns={'item_id':'NewsID'})\n",
    "    results_categories = results_categories.merge(news[['NewsID','cluster_hdbscan','proba']], on='NewsID').rename(columns={'cluster_hdbscan':'category'})\n",
    "    results_categories['proba'] = results_categories['proba'].replace(0, 1)\n",
    "    return results_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_recall(recos, list_users, categories_list, k):\n",
    "    dict_srecall = {}\n",
    "    nb_categories = len(categories_list)\n",
    "    for u in tqdm(list_users):\n",
    "        recos_user = recos[recos['user_id']==u].reset_index(drop=True)\n",
    "        recos_categories = recos_user['category'].unique().tolist()\n",
    "        s_recall_user = len(set(recos_categories))/nb_categories\n",
    "        dict_key = {u:s_recall_user}\n",
    "        dict_srecall.update(dict_key)\n",
    "    return dict_srecall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import hellinger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_hellinger(recos, list_users, users_interest_df, categories_list):\n",
    "    dict_ch = {}\n",
    "    for u in tqdm(list_users):\n",
    "        interest_user = users_interest_df.loc[u].values.tolist()\n",
    "        recos_user = recos[recos['user_id']==u].reset_index(drop=True)\n",
    "        distrib_categories = []\n",
    "        for c in categories_list:\n",
    "            prop_cat = len(recos_user[recos_user['category']==c])\n",
    "            distrib_categories.append(prop_cat/len(recos_user))\n",
    "        c_h_user = hellinger(interest_user, distrib_categories).sum()\n",
    "        dict_key = {u:c_h_user}\n",
    "        dict_ch.update(dict_key)\n",
    "    return dict_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogeneization(distrib, param=0.5):\n",
    "    n = len(distrib)\n",
    "    new_distrib = [((1-param)*p)+(param/n) for p in distrib]\n",
    "    return new_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibration_final(recos, users_list, users_interest_df, categories_list):\n",
    "    recos = get_results_categories(recos)\n",
    "    dict_ch_smooth = {}\n",
    "    for u in tqdm(users_list):\n",
    "        best_ch = 10\n",
    "        recos_user = recos[recos['user_id']==u].reset_index(drop=True)\n",
    "        interest_user = users_interest_df.loc[u].values.tolist()\n",
    "        distrib_cat_recos = []\n",
    "        for c in categories_list:\n",
    "            prop_cat = len(recos_user[recos_user['category']==c])\n",
    "            distrib_cat_recos.append(prop_cat/len(recos_user))\n",
    "        for l in np.arange(0, 1.1, 0.1):\n",
    "            new_distrib = homogeneization(interest_user, param=round(l,1))\n",
    "            c_h = hellinger(distrib_cat_recos,new_distrib)\n",
    "            if c_h < best_ch:\n",
    "                best_ch = c_h\n",
    "                optimal_lambda = l\n",
    "        dict_key = {u:best_ch}\n",
    "        dict_ch_smooth.update(dict_key)\n",
    "    return dict_ch_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_results(results, test_set, users_list, interest, similarity_matrix, categories_list, name_parameters, k=10):\n",
    "    print('Pre-processing...')\n",
    "    results_categories = get_results_categories(results)  \n",
    "    results_ratings = ca.Ratings.from_dataframe(results)\n",
    "    test_ratings = ca.Ratings.from_dataframe(test_set)\n",
    "    print('OK!')\n",
    "    #Accuracy\n",
    "    print('Accuracy metrics...')\n",
    "    sys_results, users_results = get_performances(results_ratings, test_ratings, k=k)\n",
    "    print('OK!')\n",
    "    #Instantiate the dataframe with global results\n",
    "    eval_results_global = sys_results.reset_index().copy()\n",
    "    eval_results_global = eval_results_global[eval_results_global['user_id']=='sys - fold1']\n",
    "    eval_results_global['user_id']=[name_parameters]\n",
    "    eval_results_global = eval_results_global.rename(columns={'user_id':'a_value'})\n",
    "    eval_results_global = eval_results_global.set_index('a_value')\n",
    "    # eval_results_global = eval_results_global.rename(columns={'Precision@10 - macro':'Precision', 'Recall@10 - macro':'Recall', 'F1@10 - macro':'F1 score', 'NDCG@10':'NDCG'})\n",
    "    eval_results_global = eval_results_global.rename(columns={'Precision@10 - macro':'Precision'})\n",
    "\n",
    "\n",
    "    #Instantiate the dataframe with individual results\n",
    "    eval_results_indiv = users_results.copy()\n",
    "    eval_results_indiv.index = eval_results_indiv.index.astype(int)\n",
    "    # eval_results_indiv = eval_results_indiv.rename(columns={'Precision@10 - macro':'Precision', 'Recall@10 - macro':'Recall', 'F1@10 - macro':'F1 score', 'NDCG@10':'NDCG'})\n",
    "    eval_results_indiv = eval_results_indiv.rename(columns={'Precision@10 - macro':'Precision'})\n",
    "\n",
    "\n",
    "    print('ILS...')\n",
    "    #ILS\n",
    "    dict_ils = compute_ils(results, similarity_matrix, users_list)\n",
    "    eval_results_global['ILS'] = np.mean(list(dict_ils.values()))\n",
    "    eval_results_indiv['ILS'] = eval_results_indiv.index.map(dict_ils)\n",
    "    print('OK!')    \n",
    "    # print('alpha NDCG')\n",
    "    # #alpha-NDCG\n",
    "    # dict_alpha_ndcg = alpha_ndcg(results_categories, users_list, interest, alpha=0.5, k=k)\n",
    "    # eval_results_global['alpha_ndcg'] = np.mean(list(dict_alpha_ndcg.values()))\n",
    "    # eval_results_indiv['alpha_ndcg'] = eval_results_indiv.index.map(dict_alpha_ndcg)\n",
    "    # print('OK!')\n",
    "    # print('NDCG IA')\n",
    "    # #NDCG-IA\n",
    "    # dict_ndcg_ia = ndcg_ia(results_categories, users_list, interest, k=k)\n",
    "    # eval_results_global['ndcg_ia'] = np.mean(list(dict_ndcg_ia.values()))\n",
    "    # eval_results_indiv['ndcg_ia'] = eval_results_indiv.index.map(dict_ndcg_ia)\n",
    "    # print('OK!')\n",
    "    print('S-Recall')\n",
    "    #S-Recall\n",
    "    dict_srecall = s_recall(results_categories, users_list, categories_list, k=k)\n",
    "    eval_results_global['s_recall'] = np.mean(list(dict_srecall.values()))\n",
    "    eval_results_indiv['s_recall'] = eval_results_indiv.index.map(dict_srecall)\n",
    "    print('OK!')\n",
    "    # print('Calibration KL')\n",
    "    # #C_KL\n",
    "    # dict_ckl = calibration_kl(results_categories, users_list, interest, categories_list, alpha=0.01)\n",
    "    # eval_results_global['c_kl'] = np.mean(list(dict_ckl.values()))\n",
    "    # eval_results_indiv['c_kl'] = eval_results_indiv.index.map(dict_ckl)\n",
    "    # print('OK!')\n",
    "    print('Calibration Hellinger')\n",
    "    #C_KL\n",
    "    dict_ch = calibration_hellinger(results_categories, users_list, interest, categories_list)\n",
    "    eval_results_global['c_hell'] = np.mean(list(dict_ch.values()))\n",
    "    eval_results_indiv['c_hell'] = eval_results_indiv.index.map(dict_ch)\n",
    "    print('OK!')\n",
    "\n",
    "    # eval_results_global.columns = ['Precision', 'Recall', 'F1-score', 'MRR', 'NDCG', 'ILS', 'alpha_ndcg', 'ndcg_ia', 's_recall', 'c_kl', 'c_hell']\n",
    "    eval_results_global.columns = ['Precision','ILS', 's_recall','C_h']\n",
    "\n",
    "    eval_results_global = eval_results_global.round(3)\n",
    "\n",
    "    # eval_results_indiv.columns = ['Precision', 'Recall', 'F1-score', 'NDCG', 'ILS', 'alpha_ndcg', 'ndcg_ia', 's_recall', 'c_kl', 'c_hell']\n",
    "    eval_results_indiv.columns = ['Precision','ILS', 's_recall','C_h']\n",
    "\n",
    "    eval_results_indiv = eval_results_indiv.round(3)\n",
    "    \n",
    "    return eval_results_global, eval_results_indiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_baseline_k20 = pd.read_csv('../reco/report_baseline_10k_cv_k20/CentroidVector_1/rs_rank_split0.csv')\n",
    "test_baseline_k20 = pd.read_csv('../reco/report_baseline_10k_cv_k20/HoldOutPartitioning_test_split0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_greedy_0 = pd.read_csv('../re_ranking/greedy/greedy_lambda_0.csv')\n",
    "results_greedy_01 = pd.read_csv('../re_ranking/greedy/greedy_lambda_01.csv')\n",
    "results_greedy_02 = pd.read_csv('../re_ranking/greedy/greedy_lambda_02.csv')\n",
    "results_greedy_03 = pd.read_csv('../re_ranking/greedy/greedy_lambda_03.csv')\n",
    "results_greedy_04 = pd.read_csv('../re_ranking/greedy/greedy_lambda_04.csv')\n",
    "results_greedy_05 = pd.read_csv('../re_ranking/greedy/greedy_lambda_05.csv')\n",
    "results_greedy_06 = pd.read_csv('../re_ranking/greedy/greedy_lambda_06.csv')\n",
    "results_greedy_07 = pd.read_csv('../re_ranking/greedy/greedy_lambda_07.csv')\n",
    "results_greedy_08 = pd.read_csv('../re_ranking/greedy/greedy_lambda_08.csv')\n",
    "results_greedy_09 = pd.read_csv('../re_ranking/greedy/greedy_lambda_09.csv')\n",
    "results_greedy_1 = pd.read_csv('../re_ranking/greedy/greedy_lambda_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_a_0_k20 = pd.read_csv('../re_ranking/ADF/div_a_0_k20.csv')\n",
    "results_a_0_k20 = results_a_0_k20[['user_id','item_id','score']]\n",
    "\n",
    "results_a_01_k20 = pd.read_csv('../re_ranking/ADF/div_a_01_k20.csv')\n",
    "results_a_01_k20 = results_a_01_k20[['user_id','item_id','score']]\n",
    "\n",
    "results_a_02_k20 = pd.read_csv('../re_ranking/ADF/div_a_02_k20.csv')\n",
    "results_a_02_k20 = results_a_02_k20[['user_id','item_id','score']]\n",
    "\n",
    "results_a_03_k20 = pd.read_csv('../re_ranking/ADF/div_a_03_k20.csv')\n",
    "results_a_03_k20 = results_a_03_k20[['user_id','item_id','score']]\n",
    "\n",
    "results_a_04_k20 = pd.read_csv('../re_ranking/ADF/div_a_04_k20.csv')\n",
    "results_a_04_k20 = results_a_04_k20[['user_id','item_id','score']]\n",
    "\n",
    "results_a_05_k20 = pd.read_csv('../re_ranking/ADF/div_a_05_k20.csv')\n",
    "results_a_05_k20 = results_a_05_k20[['user_id','item_id','score']]\n",
    "\n",
    "results_a_06_k20 = pd.read_csv('../re_ranking/ADF/div_a_06_k20.csv')\n",
    "results_a_06_k20 = results_a_06_k20[['user_id','item_id','score']]\n",
    "\n",
    "results_a_07_k20 = pd.read_csv('../re_ranking/ADF/div_a_07_k20.csv')\n",
    "results_a_07_k20 = results_a_07_k20[['user_id','item_id','score']]\n",
    "\n",
    "results_a_08_k20 = pd.read_csv('../re_ranking/ADF/div_a_08_k20.csv')\n",
    "results_a_08_k20 = results_a_08_k20[['user_id','item_id','score']]\n",
    "\n",
    "results_a_09_k20 = pd.read_csv('../re_ranking/ADF/div_a_09_k20.csv')\n",
    "results_a_09_k20 = results_a_09_k20[['user_id','item_id','score']]\n",
    "\n",
    "results_a_1_k20 = pd.read_csv('../re_ranking/ADF/div_a_1_k20.csv')\n",
    "results_a_1_k20 = results_a_1_k20[['user_id','item_id','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_a0 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_0_k20.csv', index_col=0)\n",
    "entropy_a01 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_01_k20.csv', index_col=0)\n",
    "entropy_a02 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_02_k20.csv', index_col=0)\n",
    "entropy_a03 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_03_k20.csv', index_col=0)\n",
    "entropy_a04 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_04_k20.csv', index_col=0)\n",
    "entropy_a05 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_05_k20.csv', index_col=0)\n",
    "entropy_a06 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_06_k20.csv', index_col=0)\n",
    "entropy_a07 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_07_k20.csv', index_col=0)\n",
    "entropy_a08 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_08_k20.csv', index_col=0)\n",
    "entropy_a09 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_09_k20.csv', index_col=0)\n",
    "entropy_a1 = pd.read_csv('../re_ranking/ADF/entropy/entropy_a_1_k20.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_glob_a06 = pd.read_csv('../re_ranking/no_pers/div_global_0.6_k20.csv')\n",
    "results_glob_a06 = results_glob_a06[['user_id','item_id','score']]\n",
    "\n",
    "results_glob_a07 = pd.read_csv('../re_ranking/no_pers/div_global_0.7_k20.csv')\n",
    "results_glob_a07 = results_glob_a07[['user_id','item_id','score']]\n",
    "\n",
    "results_glob_a08 = pd.read_csv('../re_ranking/no_pers/div_global_0.8_k20.csv')\n",
    "results_glob_a08 = results_glob_a08[['user_id','item_id','score']]\n",
    "\n",
    "results_glob_a09 = pd.read_csv('../re_ranking/no_pers/div_global_0.9_k20.csv')\n",
    "results_glob_a09 = results_glob_a09[['user_id','item_id','score']]\n",
    "\n",
    "results_glob_a1 = pd.read_csv('../re_ranking/no_pers/div_global_1_k20.csv')\n",
    "results_glob_a1 = results_glob_a1[['user_id','item_id','score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('../reco/report_baseline_10k_cv_complete/HoldOutPartitioning_test_split0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_list = [int(i) for i in test_set['user_id'].unique().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# News info\n",
    "news = pd.read_csv('../data/news_thematic_clustering_large_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "news['cluster_hdbscan'] = news['cluster_hdbscan']+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings df\n",
    "embeddings_lda_128 = pd.read_json('../reco/news_codified_lda_128/contents.json')\n",
    "embeddings_lda_128['lda_128#0'] = embeddings_lda_128['lda_128#0'].apply(ast.literal_eval)\n",
    "news_embeddings_lda = embeddings_to_df(embeddings_lda_128['lda_128#0'])\n",
    "news_embeddings_lda.index = embeddings_lda_128['content_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_interest = pd.read_csv('../user_profile/categories_distribution_subprofiles_10k.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_interest.columns = users_interest.columns.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix = pd.DataFrame(cosine_similarity(news_embeddings_lda))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_matrix.index = news_embeddings_lda.index.tolist()\n",
    "similarity_matrix.columns = news_embeddings_lda.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_list = users_interest.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:27<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:20<00:00, 124.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:06<00:00, 1519.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:40<00:00, 248.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_baseline_k20_global, eval_baseline_k20_ind = get_all_results(results_baseline_k20, test_baseline_k20, users_list, users_interest, similarity_matrix, categories_list, 'baseline_k20', k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:12<00:00, 137.16it/s]\n"
     ]
    }
   ],
   "source": [
    "ch_baseline = calibration_final(results_baseline_k20, users_list, users_interest, categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl_baseline = np.mean(list(ch_baseline.values())).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_baseline_k20_global['C_h'] = chl_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>ILS</th>\n",
       "      <th>s_recall</th>\n",
       "      <th>C_h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline_k20</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Precision   ILS  s_recall   C_h\n",
       "a_value                                      \n",
       "baseline_k20      0.224  0.55     0.383  0.36"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_baseline_k20_global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_baseline_k20_global.to_csv('baseline/complete_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eval_baseline_k20_ind.to_csv('baseline/ind_baseline.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:20<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:48<00:00, 92.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:06<00:00, 1501.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:39<00:00, 252.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:24<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:33<00:00, 107.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1206.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:46<00:00, 217.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:33<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:43<00:00, 96.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1206.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:35<00:00, 279.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:27<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:09<00:00, 77.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:10<00:00, 967.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:54<00:00, 184.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:26<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:08<00:00, 78.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:16<00:00, 606.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:51<00:00, 194.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:25<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:41<00:00, 98.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:13<00:00, 732.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:39<00:00, 100.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:30<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:27<00:00, 114.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 829.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:22<00:00, 120.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:40<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:23<00:00, 120.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1016.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:54<00:00, 182.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:37<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:49<00:00, 90.94it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1348.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:41<00:00, 240.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:24<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:41<00:00, 98.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:19<00:00, 500.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:02<00:00, 160.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:20<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:16<00:00, 131.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1036.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:22<00:00, 121.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_a_0_k20_global, eval_a_0_k20_ind = get_all_results(results_a_0_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_0_k20', k=20)\n",
    "eval_a_01_k20_global, eval_a_01_k20_ind = get_all_results(results_a_01_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_01_k20', k=20)\n",
    "eval_a_02_k20_global, eval_a_02_k20_ind = get_all_results(results_a_02_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_02_k20', k=20)\n",
    "eval_a_03_k20_global, eval_a_03_k20_ind = get_all_results(results_a_03_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_03_k20', k=20)\n",
    "eval_a_04_k20_global, eval_a_04_k20_ind = get_all_results(results_a_04_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_04_k20', k=20)\n",
    "eval_a_05_k20_global, eval_a_05_k20_ind = get_all_results(results_a_05_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_05_k20', k=20)\n",
    "eval_a_06_k20_global, eval_a_06_k20_ind = get_all_results(results_a_06_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_06_k20', k=20)\n",
    "eval_a_07_k20_global, eval_a_07_k20_ind = get_all_results(results_a_07_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_07_k20', k=20)\n",
    "eval_a_08_k20_global, eval_a_08_k20_ind = get_all_results(results_a_08_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_08_k20', k=20)\n",
    "eval_a_09_k20_global, eval_a_09_k20_ind = get_all_results(results_a_09_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_09_k20', k=20)\n",
    "eval_a_1_k20_global, eval_a_1_k20_ind = get_all_results(results_a_1_k20, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_1_k20', k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:01<00:00, 8731.72it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 8157.38it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 6418.06it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 5803.80it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 6239.88it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 7779.49it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 7858.08it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 8164.77it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 7177.62it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 6247.58it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 5717.04it/s]\n"
     ]
    }
   ],
   "source": [
    "c_hellinger_a0 = calibration_hellinger_target(entropy_a0, users_list, users_interest)\n",
    "c_hellinger_a01 = calibration_hellinger_target(entropy_a01, users_list, users_interest)\n",
    "c_hellinger_a02 = calibration_hellinger_target(entropy_a02, users_list, users_interest)\n",
    "c_hellinger_a03 = calibration_hellinger_target(entropy_a03, users_list, users_interest)\n",
    "c_hellinger_a04 = calibration_hellinger_target(entropy_a04, users_list, users_interest)\n",
    "c_hellinger_a05 = calibration_hellinger_target(entropy_a05, users_list, users_interest)\n",
    "c_hellinger_a06 = calibration_hellinger_target(entropy_a06, users_list, users_interest)\n",
    "c_hellinger_a07 = calibration_hellinger_target(entropy_a07, users_list, users_interest)\n",
    "c_hellinger_a08 = calibration_hellinger_target(entropy_a08, users_list, users_interest)\n",
    "c_hellinger_a09 = calibration_hellinger_target(entropy_a09, users_list, users_interest)\n",
    "c_hellinger_a1 = calibration_hellinger_target(entropy_a1, users_list, users_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl_a0 = abs(eval_a_0_k20_global['C_h'][0] - np.mean(list(c_hellinger_a0.values()))).round(3)\n",
    "chl_a01 = abs(eval_a_01_k20_global['C_h'][0] - np.mean(list(c_hellinger_a01.values()))).round(3)\n",
    "chl_a02 = abs(eval_a_02_k20_global['C_h'][0] - np.mean(list(c_hellinger_a02.values()))).round(3)\n",
    "chl_a03 = abs(eval_a_03_k20_global['C_h'][0] - np.mean(list(c_hellinger_a03.values()))).round(3)\n",
    "chl_a04 = abs(eval_a_04_k20_global['C_h'][0] - np.mean(list(c_hellinger_a04.values()))).round(3)\n",
    "chl_a05 = abs(eval_a_05_k20_global['C_h'][0] - np.mean(list(c_hellinger_a05.values()))).round(3)\n",
    "chl_a06 = abs(eval_a_06_k20_global['C_h'][0] - np.mean(list(c_hellinger_a06.values()))).round(3)\n",
    "chl_a07 = abs(eval_a_07_k20_global['C_h'][0] - np.mean(list(c_hellinger_a07.values()))).round(3)\n",
    "chl_a08 = abs(eval_a_08_k20_global['C_h'][0] - np.mean(list(c_hellinger_a08.values()))).round(3)\n",
    "chl_a09 = abs(eval_a_09_k20_global['C_h'][0] - np.mean(list(c_hellinger_a09.values()))).round(3)\n",
    "chl_a1 = abs(eval_a_1_k20_global['C_h'][0] - np.mean(list(c_hellinger_a1.values()))).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl = [chl_a0, chl_a01, chl_a02, chl_a03, chl_a04, chl_a05, chl_a06, chl_a07, chl_a08, chl_a09, chl_a1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results = pd.concat([eval_a_0_k20_global, eval_a_01_k20_global, eval_a_02_k20_global, eval_a_03_k20_global, eval_a_04_k20_global, eval_a_05_k20_global, eval_a_06_k20_global, eval_a_07_k20_global, eval_a_08_k20_global, eval_a_09_k20_global, eval_a_1_k20_global])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results['C_h'] = chl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results = complete_results.iloc[::-1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results.index = np.arange(0, 1.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>ILS</th>\n",
       "      <th>s_recall</th>\n",
       "      <th>C_h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.227</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.552</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.222</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.220</td>\n",
       "      <td>0.407</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.217</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.215</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.176</td>\n",
       "      <td>0.298</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.171</td>\n",
       "      <td>0.291</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.162</td>\n",
       "      <td>0.276</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.123</td>\n",
       "      <td>0.206</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Precision    ILS  s_recall    C_h\n",
       "0.0      0.227  0.438     0.525  0.141\n",
       "0.1      0.225  0.430     0.552  0.038\n",
       "0.2      0.225  0.428     0.559  0.030\n",
       "0.3      0.222  0.419     0.588  0.016\n",
       "0.4      0.220  0.407     0.622  0.055\n",
       "0.5      0.217  0.398     0.646  0.089\n",
       "0.6      0.215  0.393     0.661  0.110\n",
       "0.7      0.176  0.298     1.000  0.072\n",
       "0.8      0.171  0.291     1.000  0.041\n",
       "0.9      0.162  0.276     1.000  0.003\n",
       "1.0      0.123  0.206     1.000  0.011"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results.to_csv('ADF/ADF_complete.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No personalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing NDCG@20:  80%|████████  | 4/5 [01:33<00:23]             C:\\Users\\ctreuill.BIDOUILLE\\AppData\\Roaming\\Python\\Python39\\site-packages\\clayrs\\evaluation\\metrics\\ranking_metrics.py:205: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return actual / ideal\n",
      "Performing NDCG@20:  100%|██████████| 5/5 [01:55<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [02:56<00:00, 56.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "alpha NDCG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:23<00:00, 428.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "NDCG IA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:29<00:00, 340.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 787.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration KL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:03<00:00, 156.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:02<00:00, 158.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing NDCG@20:  80%|████████  | 4/5 [01:37<00:24]             C:\\Users\\ctreuill.BIDOUILLE\\AppData\\Roaming\\Python\\Python39\\site-packages\\clayrs\\evaluation\\metrics\\ranking_metrics.py:205: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return actual / ideal\n",
      "Performing NDCG@20:  100%|██████████| 5/5 [02:04<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:57<00:00, 85.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "alpha NDCG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:21<00:00, 471.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "NDCG IA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:28<00:00, 350.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 803.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration KL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:08<00:00, 146.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:57<00:00, 173.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing NDCG@20:  80%|████████  | 4/5 [01:54<00:28]             C:\\Users\\ctreuill.BIDOUILLE\\AppData\\Roaming\\Python\\Python39\\site-packages\\clayrs\\evaluation\\metrics\\ranking_metrics.py:205: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return actual / ideal\n",
      "Performing NDCG@20:  100%|██████████| 5/5 [02:21<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:51<00:00, 89.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "alpha NDCG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:21<00:00, 462.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "NDCG IA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:25<00:00, 395.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1011.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration KL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:02<00:00, 159.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:01<00:00, 161.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing NDCG@20:  80%|████████  | 4/5 [01:41<00:25]             C:\\Users\\ctreuill.BIDOUILLE\\AppData\\Roaming\\Python\\Python39\\site-packages\\clayrs\\evaluation\\metrics\\ranking_metrics.py:205: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return actual / ideal\n",
      "Performing NDCG@20:  100%|██████████| 5/5 [02:08<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:54<00:00, 87.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "alpha NDCG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:22<00:00, 449.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "NDCG IA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:32<00:00, 304.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:15<00:00, 638.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration KL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:16<00:00, 130.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:09<00:00, 144.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing NDCG@20:  80%|████████  | 4/5 [01:50<00:28]             C:\\Users\\ctreuill.BIDOUILLE\\AppData\\Roaming\\Python\\Python39\\site-packages\\clayrs\\evaluation\\metrics\\ranking_metrics.py:205: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return actual / ideal\n",
      "Performing NDCG@20:  100%|██████████| 5/5 [02:19<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:54<00:00, 87.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "alpha NDCG\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 383.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "NDCG IA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:29<00:00, 340.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:11<00:00, 838.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration KL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:59<00:00, 169.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:01<00:00, 163.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    }
   ],
   "source": [
    "eval_a_06_k20_nopers, eval_a_06_k20_ind_nopers = get_all_results(results_glob_a06, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_06_k20_no_pers', k=20)\n",
    "eval_a_07_k20_nopers, eval_a_07_k20_ind_nopers = get_all_results(results_glob_a07, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_07_k20_no_pers', k=20)\n",
    "eval_a_08_k20_nopers, eval_a_08_k20_ind_nopers = get_all_results(results_glob_a08, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_08_k20_no_pers', k=20)\n",
    "eval_a_09_k20_nopers, eval_a_09_k20_ind_nopers = get_all_results(results_glob_a09, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_09_k20_no_pers', k=20)\n",
    "eval_a_1_k20_nopers, eval_a_1_k20_ind_nopers = get_all_results(results_glob_a1, test_set, users_list, users_interest, similarity_matrix, categories_list, 'a_1_k20_no_pers', k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results_no_pers = pd.concat([eval_a_06_k20_nopers, eval_a_07_k20_nopers, eval_a_08_k20_nopers, eval_a_09_k20_nopers, eval_a_1_k20_nopers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>MRR</th>\n",
       "      <th>NDCG</th>\n",
       "      <th>ILS</th>\n",
       "      <th>alpha_ndcg</th>\n",
       "      <th>ndcg_ia</th>\n",
       "      <th>s_recall</th>\n",
       "      <th>c_kl</th>\n",
       "      <th>c_hell</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a_06_k20_no_pers</th>\n",
       "      <td>0.226</td>\n",
       "      <td>0.630</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.433</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.131</td>\n",
       "      <td>0.139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_07_k20_no_pers</th>\n",
       "      <td>0.223</td>\n",
       "      <td>0.623</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.422</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.423</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.558</td>\n",
       "      <td>0.114</td>\n",
       "      <td>0.134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_08_k20_no_pers</th>\n",
       "      <td>0.211</td>\n",
       "      <td>0.598</td>\n",
       "      <td>0.262</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.660</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_09_k20_no_pers</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0.298</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.316</td>\n",
       "      <td>0.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_1_k20_no_pers</th>\n",
       "      <td>0.123</td>\n",
       "      <td>0.373</td>\n",
       "      <td>0.153</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.576</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.676</td>\n",
       "      <td>0.438</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Precision  Recall  F1-score    MRR   NDCG    ILS  \\\n",
       "a_value                                                              \n",
       "a_06_k20_no_pers      0.226   0.630     0.280  0.424  0.564  0.433   \n",
       "a_07_k20_no_pers      0.223   0.623     0.276  0.422  0.564  0.423   \n",
       "a_08_k20_no_pers      0.211   0.598     0.262  0.418  0.565  0.385   \n",
       "a_09_k20_no_pers      0.175   0.534     0.220  0.405  0.567  0.298   \n",
       "a_1_k20_no_pers       0.123   0.373     0.153  0.374  0.576  0.206   \n",
       "\n",
       "                  alpha_ndcg  ndcg_ia  s_recall   c_kl  c_hell  \n",
       "a_value                                                         \n",
       "a_06_k20_no_pers       0.873    0.560     0.528  0.131   0.139  \n",
       "a_07_k20_no_pers       0.874    0.559     0.558  0.114   0.134  \n",
       "a_08_k20_no_pers       0.858    0.550     0.660  0.115   0.157  \n",
       "a_09_k20_no_pers       0.809    0.519     0.930  0.316   0.349  \n",
       "a_1_k20_no_pers        0.676    0.438     0.945  0.820   0.522  "
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_results_no_pers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results_no_pers.to_csv('no_pers/complete_no_pers.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:24<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:43<00:00, 96.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1309.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:43<00:00, 229.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:25<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:22<00:00, 121.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:13<00:00, 715.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:59<00:00, 167.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:24<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:09<00:00, 143.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1235.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:51<00:00, 194.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:33<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:14<00:00, 134.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1381.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:42<00:00, 236.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:28<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:34<00:00, 105.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1010.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:42<00:00, 235.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:24<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:16<00:00, 130.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:08<00:00, 1160.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:05<00:00, 152.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:24<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:09<00:00, 143.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1348.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:49<00:00, 203.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:29<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:36<00:00, 103.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:07<00:00, 1289.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:43<00:00, 229.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:25<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:31<00:00, 109.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:12<00:00, 780.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:58<00:00, 171.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:24<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:13<00:00, 136.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:09<00:00, 1084.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:56<00:00, 176.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Pre-processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[39mINFO\u001b[0m - Performing evaluation on metrics chosen\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Accuracy metrics...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing Precision@20 - macro:  100%|██████████| 1/1 [00:32<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "ILS...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [01:28<00:00, 113.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "S-Recall\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:06<00:00, 1541.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n",
      "Calibration Hellinger\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:37<00:00, 267.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_greedy_0, eval_greedy_0_ind = get_all_results(results_greedy_0, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_0', k=20)\n",
    "eval_greedy_01, eval_greedy_01_ind = get_all_results(results_greedy_01, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_01', k=20)\n",
    "eval_greedy_02, eval_greedy_02_ind = get_all_results(results_greedy_02, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_02', k=20)\n",
    "eval_greedy_03, eval_greedy_03_ind = get_all_results(results_greedy_03, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_03', k=20)\n",
    "eval_greedy_04, eval_greedy_04_ind = get_all_results(results_greedy_04, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_04', k=20)\n",
    "eval_greedy_05, eval_greedy_05_ind = get_all_results(results_greedy_05, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_05', k=20)\n",
    "eval_greedy_06, eval_greedy_06_ind = get_all_results(results_greedy_06, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_06', k=20)\n",
    "eval_greedy_07, eval_greedy_07_ind = get_all_results(results_greedy_07, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_07', k=20)\n",
    "eval_greedy_08, eval_greedy_08_ind = get_all_results(results_greedy_08, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_08', k=20)\n",
    "eval_greedy_09, eval_greedy_09_ind = get_all_results(results_greedy_09, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_09', k=20)\n",
    "eval_greedy_1, eval_greedy_1_ind = get_all_results(results_greedy_1, test_set, users_list, users_interest, similarity_matrix, categories_list, 'greedy_1', k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results_greedy = pd.concat([eval_greedy_0, eval_greedy_01, eval_greedy_02, eval_greedy_03, eval_greedy_04, eval_greedy_05, eval_greedy_06, eval_greedy_07, eval_greedy_08, eval_greedy_09, eval_greedy_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:53<00:00, 187.65it/s]\n",
      "100%|██████████| 10000/10000 [00:54<00:00, 184.30it/s]\n",
      "100%|██████████| 10000/10000 [00:42<00:00, 234.22it/s]\n",
      "100%|██████████| 10000/10000 [00:57<00:00, 173.54it/s]\n",
      "100%|██████████| 10000/10000 [00:44<00:00, 223.21it/s]\n",
      "100%|██████████| 10000/10000 [01:08<00:00, 146.95it/s]\n",
      "100%|██████████| 10000/10000 [01:52<00:00, 89.13it/s]\n",
      "100%|██████████| 10000/10000 [01:13<00:00, 136.64it/s]\n",
      "100%|██████████| 10000/10000 [01:23<00:00, 119.25it/s]\n",
      "100%|██████████| 10000/10000 [01:09<00:00, 144.21it/s]\n",
      "100%|██████████| 10000/10000 [01:26<00:00, 115.64it/s]\n"
     ]
    }
   ],
   "source": [
    "ch_greedy0 = calibration_final(results_greedy_0, users_list, users_interest, categories_list)\n",
    "ch_greedy01 = calibration_final(results_greedy_01, users_list, users_interest, categories_list)\n",
    "ch_greedy02 = calibration_final(results_greedy_02, users_list, users_interest, categories_list)\n",
    "ch_greedy03 = calibration_final(results_greedy_03, users_list, users_interest, categories_list)\n",
    "ch_greedy04 = calibration_final(results_greedy_04, users_list, users_interest, categories_list)\n",
    "ch_greedy05 = calibration_final(results_greedy_05, users_list, users_interest, categories_list)\n",
    "ch_greedy06 = calibration_final(results_greedy_06, users_list, users_interest, categories_list)\n",
    "ch_greedy07 = calibration_final(results_greedy_07, users_list, users_interest, categories_list)\n",
    "ch_greedy08 = calibration_final(results_greedy_08, users_list, users_interest, categories_list)\n",
    "ch_greedy09 = calibration_final(results_greedy_09, users_list, users_interest, categories_list)\n",
    "ch_greedy1 = calibration_final(results_greedy_1, users_list, users_interest, categories_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl_greedy0 = np.mean(list(ch_greedy0.values())).round(3)\n",
    "chl_greedy01 = np.mean(list(ch_greedy01.values())).round(3)\n",
    "chl_greedy02 = np.mean(list(ch_greedy02.values())).round(3)\n",
    "chl_greedy03 = np.mean(list(ch_greedy03.values())).round(3)\n",
    "chl_greedy04 = np.mean(list(ch_greedy04.values())).round(3)\n",
    "chl_greedy05 = np.mean(list(ch_greedy05.values())).round(3)\n",
    "chl_greedy06 = np.mean(list(ch_greedy06.values())).round(3)\n",
    "chl_greedy07 = np.mean(list(ch_greedy07.values())).round(3)\n",
    "chl_greedy08 = np.mean(list(ch_greedy08.values())).round(3)\n",
    "chl_greedy09 = np.mean(list(ch_greedy09.values())).round(3)\n",
    "chl_greedy1 = np.mean(list(ch_greedy1.values())).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "chl_greedy_complete = [chl_greedy0, chl_greedy01, chl_greedy02, chl_greedy03, chl_greedy04, chl_greedy05, chl_greedy06, chl_greedy07, chl_greedy08, chl_greedy09, chl_greedy1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36, 0.36, 0.359, 0.359, 0.356, 0.349, 0.348, 0.344, 0.335, 0.316, 0.37]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chl_greedy_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results_greedy['C_h'] = chl_greedy_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>ILS</th>\n",
       "      <th>s_recall</th>\n",
       "      <th>C_h</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a_value</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>greedy_0</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy_01</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy_02</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy_03</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.384</td>\n",
       "      <td>0.359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy_04</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.545</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy_05</th>\n",
       "      <td>0.224</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy_06</th>\n",
       "      <td>0.223</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy_07</th>\n",
       "      <td>0.223</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy_08</th>\n",
       "      <td>0.222</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy_09</th>\n",
       "      <td>0.217</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>greedy_1</th>\n",
       "      <td>0.173</td>\n",
       "      <td>0.152</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Precision    ILS  s_recall    C_h\n",
       "a_value                                     \n",
       "greedy_0       0.224  0.550     0.383  0.360\n",
       "greedy_01      0.224  0.550     0.383  0.360\n",
       "greedy_02      0.224  0.549     0.383  0.359\n",
       "greedy_03      0.225  0.548     0.384  0.359\n",
       "greedy_04      0.225  0.545     0.386  0.356\n",
       "greedy_05      0.224  0.528     0.395  0.349\n",
       "greedy_06      0.223  0.519     0.399  0.348\n",
       "greedy_07      0.223  0.508     0.406  0.344\n",
       "greedy_08      0.222  0.475     0.427  0.335\n",
       "greedy_09      0.217  0.386     0.492  0.316\n",
       "greedy_1       0.173  0.152     0.613  0.370"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_results_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_results_greedy.to_csv('greedy/complete_greedy.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
